{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import sparse\n\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ucl_a=np.matrix( '0.0 1.0 5.0 0.0 4.0 5.0 ;0.0 0.0 3.0 -1.0 3.0 5.0 ;-2.0 -1.0 0.0 1.0 1.0 5.0;-4.0 0.0 -1.0 0.0 1.0 4.0; -5.0 -3.0 -1.0 -3.0 0.0 2.0; -10.0 -6.0 -2.0 -3.0 -3.0 0.0')\nprint(ucl_a)\n\nu, s, vt = np.linalg.svd(ucl_a)\n\nprint(u,s,vt)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 83,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[  0.   1.   5.   0.   4.   5.]\n [  0.   0.   3.  -1.   3.   5.]\n [ -2.  -1.   0.   1.   1.   5.]\n [ -4.   0.  -1.   0.   1.   4.]\n [ -5.  -3.  -1.  -3.   0.   2.]\n [-10.  -6.  -2.  -3.  -3.   0.]]\n[[-0.08511855 -0.66108906  0.42033819 -0.42461485 -0.25685697  0.36436057]\n [-0.0016112  -0.54787869  0.23727552  0.35650192  0.25834022 -0.67059182]\n [ 0.164471   -0.37396178 -0.56787714 -0.18327623  0.64220232  0.25417206]\n [ 0.26238014 -0.29315107 -0.59413033  0.04388905 -0.66927545 -0.20584555]\n [ 0.44724183 -0.11123002  0.16549362  0.70590033 -0.03363178  0.51067419]\n [ 0.8347652   0.15694943  0.25328383 -0.39849331  0.07615963 -0.22312337]] [14.81225504 11.88878842  3.94778988  1.96487448  1.66261568  0.20914819] [[-0.80759639 -0.44557066 -0.18967934 -0.2484388  -0.16356404  0.15748517]\n [ 0.07630581 -0.07529226 -0.40867067  0.00309188 -0.45639246 -0.7830665 ]\n [ 0.03849476 -0.26039089  0.69294128 -0.52218712  0.11938841 -0.40449246]\n [ 0.32899186  0.01624544 -0.51218092 -0.74406749  0.21738748  0.16815887]\n [ 0.4807243  -0.75490791  0.02485467  0.15414179 -0.30551813  0.28513054]\n [-0.03394347 -0.39729659 -0.23215376  0.29697324  0.78108929 -0.29801729]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "def FunkSVD(ratings_mat, latent_features=4, learning_rate=0.0001, iters=100):\n    '''\n    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n    \n    INPUT:\n    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n    latent_features - (int) the number of latent features used\n    learning_rate - (float) the learning rate \n    iters - (int) the number of iterations\n    \n    OUTPUT:\n    user_mat - (numpy array) a user by latent feature matrix\n    movie_mat - (numpy array) a latent feature by movie matrix\n    '''\n    \n    # Set up useful values to be used through the rest of the function\n    n_users = ratings_mat.shape[0]\n    n_movies = ratings_mat.shape[1]\n    num_ratings = np.count_nonzero(~np.isnan(ratings_mat)) #-n_users\n    \n    # initialize the user and movie matrices with random values\n    home_mat = np.random.rand(n_users, latent_features)\n    away_mat = np.random.rand(latent_features, n_movies)\n    \n    # initialize sse at 0 for first iteration\n    sse_accum = 0\n    \n    # header for running results\n    print(\"Optimizaiton Statistics\")\n    print(\"Iterations | Mean Squared Error \")\n    #print(home_mat)\n    #print(away_mat)\n    # for each iteration\n    for iteration in range(iters):\n\n        # update our sse\n        old_sse = sse_accum\n        sse_accum = 0\n        \n        # For each user-movie pair\n        for i in range(n_users):\n            for j in range(n_movies):\n \n                \n                # if the rating exists\n                #if i,j>=0:\n                    \n                    # compute the error as the actual minus the dot product of the user and movie latent features\n                    diff = ratings_mat[i, j] - np.dot(home_mat[i, :], away_mat[:, j])\n                    \n                    # Keep track of the sum of squared errors for the matrix\n                    sse_accum += diff**2\n                    \n                    # update the values in each matrix in the direction of the gradient\n                    for k in range(latent_features):\n                        home_mat[i, k] += learning_rate * (2*diff*away_mat[k, j])\n                        away_mat[k, j] += learning_rate * (2*diff*home_mat[i, k])\n\n        # print results for iteration\n        if iteration in {0,1,iters-1}:\n            print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n        \n    return home_mat, away_mat ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "home_mat, away_mat = FunkSVD(ucl_a, latent_features=6, learning_rate=0.005, iters=500)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 106,
      "outputs": [
        {
          "name": "stdout",
          "text": "Optimizaiton Statistics\nIterations | Mean Squared Error \n1 \t\t 11.968661\n2 \t\t 10.127342\n500 \t\t 0.000003\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "print(home_mat)\nprint(away_mat)\n\nprint(np.dot(home_mat, away_mat)-ucl_a)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 107,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[ 1.24167653  1.36301916  0.97504756  0.43058105  0.73869796  0.58119936]\n [ 0.38778038  0.40802045  1.59187865  0.53995948  0.79057684  0.52554284]\n [ 0.33788113 -0.60548512  0.28424658  0.31221046  1.18859717  1.50369274]\n [-0.41734952  0.39679191  0.03460311  0.10459401  0.09264511  1.98625794]\n [-0.11124066 -0.41752904  1.29275955 -0.73592158 -0.71975373  1.05744812]\n [ 1.1638132  -1.28639586  0.40129304 -0.51536231 -2.06253917  1.76668957]]\n[[-0.64240702 -0.78903003  1.55823679  0.18574101  0.23741081  0.37206813]\n [ 0.66921604  1.49431514  1.3794533   0.0983849   1.43941298  0.57053239]\n [-0.34782524 -0.64268895  0.85649905 -1.38261544  0.88353947  1.35853986]\n [ 0.72933757  0.69445826  0.53051671  0.45699298 -0.02137006  0.37663482]\n [ 1.76526855  0.78253496  0.57608726  1.08792631  1.04181896  1.61676375]\n [-2.39722501 -0.52659658 -0.52163211 -0.03105426  0.20378925  1.85881372]]\n[[ 1.19993071e-04  1.42776389e-03  9.87313111e-04 -1.01230914e-03\n  -2.94190941e-03  1.08905853e-03]\n [-2.05864927e-04 -2.45777203e-03 -1.69988927e-03  1.74047441e-03\n   5.05974932e-03 -1.87003179e-03]\n [ 8.44954137e-05  1.03043310e-03  7.11422837e-04 -7.27857470e-04\n  -2.11592659e-03  7.81078154e-04]\n [-6.74386125e-05 -8.27998686e-04 -5.71320706e-04  5.84628289e-04\n   1.69960808e-03 -6.27608600e-04]\n [ 1.55281459e-04  1.86213331e-03  1.28769057e-03 -1.31809670e-03\n  -3.83220319e-03  1.41609417e-03]\n [-5.94144669e-05 -7.10287488e-04 -4.92242310e-04  5.01131546e-04\n   1.45841003e-03 -5.35263699e-04]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}